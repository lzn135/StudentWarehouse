pyhon 疫情 大数 据分析 四 微 博 话题 抓取 及 新 冠 肺炎 疫情 文本 挖掘 和 情感 分析 思来想去 虽然 很忙 但 还是 挤时间 针对 这次 肺炎 疫情 写个 python 大数 据分析 系列 博客 包括 网络 爬虫 可视化 分析 gis 地图 显示 情感 分析 舆情 分析 主题 挖掘 威胁 情报 溯源 知识 图谱 预测 预警 及 ai 和 nlp 应用 等 希望 该 系列 线上 远程教学 对 您 有所 帮助 也 希望 早点 战胜 病毒 武汉 加油 湖北 加油 全国 加油 待到 疫情 结束 樱花 盛开 这座 英雄 的 城市 等 你们 来 首 先说 声 抱歉 最近 一直 忙着 学习 安全 知识 其他 系列 文章 更新 较慢 已经有 一些人 催 更 了 言归正传 前文 分享 了 疫情 相关 新闻 数据 爬 取 并进 行 中文 分词 处理 及 文本 聚 类 lda 主题 模型 分析 这篇 文章 将 抓取 微 博 话题 及 评论 信息 采用 snownlp 进行 简单 的 情感 分析 及 文本 挖掘 包括 随 时间 的 情感 分布 希望 这篇 基础性 文章 对 您 有所 帮助 也 非常感谢 参考文献 中 老师 的 分享 一起 加油 战胜 疫情 如果 您有 想 学习 的 知识 或 建议 可以 给 作者 留言 代码 下载 地址 下载 地址 文章 目录 一 微 博 话题 数据 抓取 爬虫 解析 爬虫 完整 代码 二 微 博 话 题词 云 分析 基本 用法 疫情 词 云 wordcloud 三 snownlp 情感 分析 用法 snownlp 中文 分词 常见 功能 情感 分析 四 snownlp 微 博 情感 分析 实例 情感 各 分数 段 出现 频率 情感 波动 分析 情感 时间 分布 五 总结 同时 推荐 前面 作者 另外 五个 python 系列 文章 从 年 开始 作者 主要 写了 三个 python 系列 文章 分 别是 基础知识 网络 爬虫 和数 据分析 年 陆续 增加了 python 图像识别 和 python 人工智能 专栏 python 基础知识 系列 python 基础知识 学习 与 提升 python 网络 爬虫 系列 python 爬虫 之 数据 分析 系列 知识 图谱 web 数据 挖掘 及 nlppython 图像识别 系列 python 图像 处理 及 图像识别 python 人工智能 系列 python 人工智能 及 知识 图谱 实战 前文 阅读 pyhon 疫情 大数 据分析 一 腾讯 实时 数据 爬 取 matplotlib 和 seaborn 可视化 分析 全国 各地区 某省 各城市 新增 趋势 pyhon 疫情 大数 据分析 二 pyecharts 绘制 全国 各地区 某省 各城市 疫情 地图 及 可视化 分析 pyhon 疫情 大数 据分析 三 新闻 信息 抓取 及 词 云 可视化 文本 聚 类 和 lda 主题 模型 文本 挖掘 一 微 博 话题 数据 抓取 该 部分内容 参考 及 修改 我 的 学生 兼 朋友 杨 友 的 文章 也 推荐 博 友 们 阅读 他 的 博客 给予 支持 作为 老师 最 开心 的 事 就是 看到 学生 成长 和 收获 他 的 博客地址 python 爬虫 爬 取 微 博 之战 疫情 用户 评 论及 详情 微 博 网址 httpsmweibocn 爬虫 解析 第一 步进 入微 博 审查 元素 定位 评论 对应 节点 后续 抓取 评论 信息 进 入微 博 后 点击 战 疫情 主 题下 并 随便 选择 一个 动态 进行 分析 我 就 选择 了 央视 新闻网 的 一条 动态 进行 分析 我们 刚 打开 该 话题 的 时候 它 显示 的 是 条 评论 但是在 审查 时 可以 看到 文章 中 的 个 div 并且 每个 div 中 装载 一条 评论 每个 页面 原始 就 只能 显示 条 评论 当 我们 把 鼠标 不断 向下 滑动 的 过程中 网页 元素 中 的 div 也 不断 随 评论 的 增加 而 增 加当 活动 到 底部 时 所有 评论 都 加载 出 来了 初步判断 该 网页 属于 ajax 加载 类型 所以 先就 不要 考虑 用 requests 请求 服务器 了 第二步 获取 ajax 加载 的 动态 链接 数据 通过 发布 id 定位 每条 话题 这些 数据 都是 通过 ajax 动态 加载 的 点击 到 战 疫情 主题 发现 它 的 url 并没有 变化 具体 浏览 几篇 文章 后 发现 它 的 的 部分 url 都是 统一 的 文章 链接 发布 时 的 id 可以 通过 刚 找到 的 id 在 浏览器 中 拼接 试试 比如 下图 所示 的 微 博 内容 比如 第三步 下拉 网页 动态 刷新 数据 发现 获取 多个 page 的 规律 接下来 是 获取 它 下一个 加载 数据 的 通道 同样是 通过 抓 包 的 方式 获取 不断 的 下拉 网页 加 载出 其他 的 ajax 数据传输 通道 再 进行 对比 可以 很明显 的 看出 它 的 当前 链接 就 只是 带 上了 amppage 当前 数字 的 标签 并且 每次 加 载出 篇 动态 文章 查看 元素 信息 如 下图 所示 每个 page 显示 个 微 博 话题 第四步 调用 jsonloads 函数 或在 线 网站 解析 json 数据 拿到 的 数据 是 json 格式 再 提取 信息 前 需 要把 str 文本 转 化为 json 数据 进行 查找 可以 使用 json 库 查看 它 的 结构 也 可以 在线 json 解析 查看 它 的 结构 更 推荐 在线 解析 方法 结构 比较 清晰 在线 解析 后 的 结果 简单 的 给它 打上 标签 每一个 等级 为 一块 一级 包括 二级 和 三级 二级 包括 三级 然后 通过 前面 的 标签 进行 迭代 输出 索引 出来 在线 网站 httpswwwjsoncn 第五步 获取 每条 微 博 的 id 值 调用 方法 如下 然后 把 拿到 的 id 加在 的 后面 就可以 访问 具体 的 文章 了 apiurl commentid 此时 提取 所有 链接 代码 如下 爬 取 战 疫情 首页 的 每个 主题 的 这是 控制 ajax 通道 的 量 chromechrome 浏览器 随机 代理 timesleep 该 链接 通过 抓 包 获得 page print apiurl reprequestsget commenturl commenturl gettitleid 输出 结果 如下 第六步 调用 requestsajax 爬 取 更多 信息 现在 需要 获取 更多 的 信息 如 用户 id 性别 之类 的 这不是 selenium 可以 完成 的 操 作了 还得 使用 ajax 的 方式 获取 json 数据 提取 详细 的 信息 这里有 个 字段 是 maxid 我们 需要 在上 一个 json 文件 底部 找到 该 值 目标 话题 链接 话题 内容 楼主 id 楼主 昵称 楼主 性别 发布 日期 发布 时间 转发 量 评论 量 点 赞 量 评 论者 id 评 论者 昵称 评 论者 性别 评论 日期 评论 时间 评论 内容 第一个 通道 现在 可以 预测 下一个 maxid 成功 的 通过 上一个 通道 拿 到了 下一个 通道 的 maxid 现在 就可以 使用 ajax 加载 数据 了 爬虫 完整 代码 sys 记录 起始 时间 文件 存储 pathosgetcwd writercsvwriter csvfile csv 头部 writerwriterow 话题 链接 话题 内容 楼主 id 楼主 昵称 楼主 性别 发布 日期 发布 时间 转发 量 评论 量 点 赞 量 评 论者 id 评 论者 昵称 评 论者 性别 评论 日期 评论 时间 评论 内容 设置 windowsntwinx applewebkit khtmllikegecko 爬 取 战 疫情 首页 的 每个 主题 的 forpageinrange 每个 页面 大约有 个 话题 chromechrome 浏览器 随机 代理 timesleep 该 链接 通过 抓 包 获得 page print apiurl reprequestsget 获取 id 值 并 写入 列表 commentid 中 commentid 爬 取 战 疫情 每个 主题 的 详情 页面 defspidertitle commentid text 话题 内容 text htmltext titletextresub lt s 正则 匹配 掉 html 标签 print 楼主 id htmltext print 楼主 昵称 screenname htmltext print 楼主 性别 gender htmltext print 发布 时间 createdat htmltext split 日期 elseprint 该 时间 不在 疫情 范围 内估计 数据 有误 url passprint 发布 时间 转发 量 repostscount htmltext print 评论 量 commentscount htmltext print 点 赞 量 attitudescount htmltext print commentcountint int commentscount 每个 ajax 一次 加载 条 数据 position 写入 数据 writerwriterow position 抓取 评论 信息 commentid 话题 编号 defgetpage tryrrequestsget erroreargs pass 抓取 评论 item 最大值 defparsepage jsondata data 抓取 评论 信息 defwritecsv jsondata 用户 用户 昵称 用户 性别 m 表示 男性 表示 女性 获取 评论 lt s 正则 匹配 掉 html 标签 评论 时间 elseprint 该 时间 不在 疫情 范围 内估计 数据 有误 评论 时间 时分秒 iflen commenttext position writerwriterow position 写入 数据 print 主 函数 defmain counttitlelen commentsid commentsid print 正在 爬 取 第 s 个 话题 一共 找到 个 s 话题 需要 爬 取 countcounttitle maxpage 获取 返回 的 最大 评论 数量 commentid print maxpagemaxpage 小于 条 评论 的 不需要 循环 try 用 评论 数量 控制 循环 forpageinrange maxpage 自定义 函数 抓取 网页 评论 信息 jsondatagetpage 自定义 函数 写入 csv 文件 writecsv jsondata 自定义 函数 获取 评论 item 最大值 jsondata timesleep 分隔符 csvfileclose ifnamemain 获取 话题 idgettitleid 主 函数 操作 main 计算 使用时间 endtimetimetime usetime print 该 次 所获 的 信息 一共 使用 s 分钟 usetime 保存 数据 截图 如 下图 所示 下图 时 抓取 的 话题 页面 网址 每个 页面 包括 个 话题 接着 抓取 每个 话题 的 内容 如下 所示 正在 爬 取 第 个 话题 一共 找到 个 话题 需要 爬 取 国家 卫 健 委 回应 健康 码 互通 互 认 国家 卫生 健康 委 规划 司 司 长毛 群 安 目前 全国 低 风险 县域 已占 各 省份 正在 按照 统一 的 数据格式 标准 和 内容 要求 加 快向 全国 一体化 平台 汇聚 本地区 防疫 健康 信息 的 目录 截至 目前 全国 绝大多数 健康 码 可 实现 一码 通行 人民日报 的 微 博 视频 人民日报 该 时间 不在 疫情 范围 内估计 数据 有误 urlmaxpagenone 分隔符 正在 爬 取 第 个 话题 一共 找到 个 话题 需要 爬 取 法国 网友 自称 自己 成了 长发 公主 度 过了 居家 隔离 后 的 第三天 全球 疫情 法国 疫情 法国 囧 事 的 微 博 视频 法国 囧 事 该 时间 不在 疫情 范围 内估计 数据 有误 urlmaxpagenone 分隔符 正在 爬 取 第 个 话题 一共 找到 个 话题 需要 爬 取 全球 疫情 意大利 疫情 意大利 罗马 还有 其他 四处 的 药店 都 遭 到了 抢劫 我们 遭受到 的 是 持械 抢劫 这是 一位 罗马 药店 药剂师 的 陈述 她说 在 当前 疫情 的 危机 情况下 我们 处在 两难 困境 之中 受到 抢劫 和 疾病 的 双重 威胁 疫情 之下 意大利 口罩 告急 价格 飙 高 市民 认为是 药店 不 卖 而 真实情况 是 药店 真的 没有 而 供货商 又 抬 高了 价格 药店 处在 两难 境地 这位 药剂 师道 出了 自己 的 苦衷 冒着危险 还在 工作 与 医护人员 一样 都是 奋斗 在 一线 做出 牺牲 的人 呼吁 民众 理解 也 请求 大家 的 帮助 nita 大 呵呵 的 微 博 视频 titleuseridt 大 呵呵 该 时间 不在 疫情 范围 内估计 数据 有误 urlmaxpagenone 最终 抓取 个 疫情 话题 内容 注意 该 爬虫 评论 写入 功能 需要 改进 下 且 只能 抓取 当天 的 战 疫情 话题 及 评论 如果 想 针对 某个 突发事件 进行 一段时间 的 分析 建议 每天 定时 运行 该 程序 从而 形成 所需 的 数据 集 也 可以 根据 需求 修 改为 热点话题 的 抓取 增加 搜索 功能 等 作者 前文 python 爬虫 selenium 爬 取 新浪 微 博 内容 及 用户 信息 python 爬虫 selenium 爬 取 新浪 微 博 客户端 用户 信息 热点话题 及 评论 上 python 爬虫 selenium 爬 取 新浪 微 博 移动 端 热点话题 及 评论 下 二 微 博 话 题词 云 分析 首先 我们 对 文本 进行 简单 的 词 云 可视化 分析 基本 用法 词 云 分析 主要 包括 两种 方法 调用 wordcloud 扩展 包 画图 兼容性 极强 之前 介绍 过 调用 pyecharts 中 的 wordcloud 子 包 画图 本文 推荐 新方法 pyecharts 绘制 词 云 的 基础 代码 如下 数据 words 背包 问题 大 整数 karatsuba 乘法 算法 穷举 搜索 傅里叶变换 状态 树 遍历 剪枝 galeshapley 最大 匹配 与 匈牙利 算法 线索 模型 关键 路径 算法 最小二乘法 曲线拟合 二分 逼近 法 牛顿 迭代法 bresenham 算法 粒 子群 优化 dijkstra a 算法 负 极大 极 搜索算法 估 值 函数 渲染 图 gtwordcloudc wordcloud add titlewordcloud 词 云 returnc 生成 图 wordcloudbase render 词 云图 html 输出 结果 如 下图 所示 出现 词频 越高 显示 越大 核心 代码 为 add namegtstr 图例 名称 attrgtlist 属性 名称 valuegtlist 属性 所 对应 的 值 shapegtlist 词 云图 轮廓 有 可选 wordgapgtint 单词 间隔 默 认为 单词 字体大小 范围 默 认为 rotatestepgtint 旋转 单词 角度 默 认为 疫情 词 云 接着 我们 将 月 日 疫情 内容 复制 至 datatxt 文本 经过 中文 分词 后 显示 前个 高频词 的 词 云 代码 如下 中文 分词 cclassfencitxtw forlineinopen linestrip n seglistjiebacut linecutallfalse print join seglist cutwords join seglist fwrite cutwords 输出 结果 print allwords 词频 统计 ccounter x gtandxrncx 输出 词频 最高 的 前个 词 print n 词频 统计 结果 for kv incmostcommon print sd kv 存储 数据 ymd fccsvfwopen ifor kv incmostcommon len c fwwrite str i str k str v n iielseprint overwritefile fwclose 词 云 分析 生成 数据 word a b c 列表 tuplewordsfor kv incmostcommon print kv wordsappend kv 渲染 图 gtwordcloudc wordcloud add setglobalopts title 全国 新型 冠状病毒 疫情 词 云图 returnc 生成 图 wordcloudbase render 疫情 词 云图 html 输出 结果 如 下图 所示 仅 月 日 的 热点话题 内容 wordcloud 另一 种方法 的 代码 如下 中文 分词 datafencitxtw forlineinopen linestrip n seglistjiebacut linecutallfalse print join seglist cutwords join seglist fwrite cutwords 输出 结果 print allwords 词频 统计 ccounter x gtandxrncx 输出 词频 最高 的 前个 词 print n 词频 统计 结果 for kv incmostcommon print sd kv 存储 数据 ymd fccsvfwopen ifor kv incmostcommon len c fwwrite str i str k str v n iielseprint overwritefile fwclose 词 云 分析 打开 本体 txt 文件 textopen datatxt read 结巴 分词 cutalltrue 设置 为 精准 模式 textcutallfalse 使用 空格 连接 进行 中文 分词 wordlist print wlspacesplit 对 分词 后 的 文本 生成 词 云 generate wlspacesplit 显示 词 云图 pltimshow mywordcloud 是否 显示 x 轴 y 轴 下标 pltaxis off pltshow 三 snownlp 情感 分析 用法 情感 分析 的 基本 流程 如 下图 所示 通常 包括 自定义 爬虫 抓取 文本 信息 使用 jieba 工具 进行 中文 分词 词性 标注 定义 情感 词典 提取 每行 文本 的 情感 词 通过 情感 词 构建 情感 矩阵 并 计算 情感 分数 结果 评估 包括 将 情感 分数 置于 到 之间 并 可视化 显示 snownlpsnownlp 是 一个 常用 的 python 文本 分析 库 是 受到 textblob 启发 而 发明 的 由于 当前 自然语言 处理 库 基本 都是 针对 英文 的 而 中文 没有 空格 分割 特征词 python 做 中文 文本 挖掘 较难 后续 开 发了 一些 针对 中文 处理 的 库 例如 等 注意 snownlp 处理 的 是 unicode 编码 所以 使 用时 请 自行 decode 成 unicodesnownlp 主要功能 包括 中文 分词 算法 是 词性 标注 原理 是 tntgram 隐 马 情感 分析 文本 分类 原理 是 朴素 贝 叶 斯 转换 拼音 繁体 转 简体 提取 文本 关键词 原理 是 textrank 提取 摘要 原理 是 textrank 分割 句子 文本 相似 原理 是 bm 推荐 官 网 给 大家 学习 安装 和 其他 库 一样 使用 pip 安装 即可 中文 分词 下面 是 最 简单 的 实例 使用 snownlp 进行 中文 分词 同时 比较 了 snownlp 和 jieba 库 的 分词 效果 u 这 本书 质量 真不 太好 print snownlp print join swords u 这 本书 质量 真不 太好 cutallfalse print jieba print join s 输出 结果 如下 所示 总体 感觉 是 snownlp 分词 速度 比较慢 准确度 较低 比如 不太好 这个 词组 但也 不影响 我们 后续 的 情感 分析 常见 功能 代码 如下 u 这 本书 质量 真不 太好 print un 中文 分词 print join swords print un 词性 标注 print stags k print un 情感 分数 print ssentiments print un 转换 拼音 print spinyin print un 输出 前个 关键词 print skeywords forkinskeywords print k print un 输出 关键 句子 print ssummary forkinssummary print k print un 输出 tf 和 idf print stf print sidf nsnownlp u 繁 體 字 繁 體 中文 的 叫法 在 臺 灣 亦 很 常 見 print un 繁简体 转换 print nhan swords 输出 分词 后 的 结果 词性 标注 主要 通过 计算 情感 分数 spinyin 转 换为 拼音 skeywords 提取 个 关键词 ssummary 输出 一个 关键 句子 stf 计算 tf 值 频率 sidf 计算 idf 值 倒 文档 输出 结果 如下 所示 gtgtgt 中文 分词 这 本书 质量 真不 太好 词性 标注 uufdur uucueur uuducfun uufud uuedud uuaud uudua uuffuw uufdur uucueur uuducfun uufud uuedud uuaud uudua uuffuw 情感 分数 转换 拼音 输出 前个 关键词 太不 质量 真 输出 关键 句子 这 本书 质量 真不 太好 输出 tf 和 繁简体 转换 繁体字 繁体中文 的 叫法 在 台湾 亦 很 常见 gtgtgt 同样 可以 进行 文本 相似 度 计算 代码 参考 下图 所示 情感 分析 snownlp 情感 分析 也是 基于 情感 词典 实现 的 其 简单 的 将 文本 分为 两类 积极 和 消极 返回值 为 情绪 的 概率 越 接近 为 积极 接近 为 消 极其 原理 参考 zhiyongwill 大神 和 邓 旭 东 老师 的 文章 也 强烈推荐 大家 学习 地址 情感 分析 深入 snownlp 原理 和 实践 自然语言 处理 库 之 snownlp 下面 简单 给出 一个 情感 分析 的 例子 u 我 今天 很 开心 print us 情感 分数 print ssentiments ssnownlp u 我 今天 很 沮丧 print us 情感 分数 print ssentiments ssnownlp u 大 傻瓜 你 脾气 真差 动不动 就 打人 print us 情感 分数 print ssentiments 输出 结果 如下 所示 当 负面 情感 特征词 越多 比如 傻瓜 差 打人 等 分数 就会 很低 同样 当 正 免 情感 词 多 分数 就 高 s 情感 分数 s 情感 分数 s 情感 分数 而在 真实 项 目中 通常 需要 根据 实际 的 数据 重新 训练 情感 分析 的 模型 导入 正面 样本 和 负面 样本 再 训练 新 模型 sentimenttrain negtxtpostxt sentimentsave 四 snownlp 微 博 情感 分析 实例 下面 的 代码 是 对 爬 取 的 疫情 话题 进行 情感 分析 本文 将 抓取 的 条 其中 条 仅 图片 微 博 疫情 话题 信息 复制 至 txt 文件 中 每 一 行为 一条 话题 再 对 其 进行 中文 分词 处理 注意 这里 仅仅 获取 序号 的 情感 分数 而其 他 情感 分析 可以 进行 时间 对比 主题 对比 等 其 方法 和 此 篇文章 类似 希望 读者 学会 举一反三 情感 各 分数 段 出现 频率 首先 统计 各 情感 分数 段 出现 的 评 率 并 绘制 对应 的 柱状图 代码 如下 i print ssentiments ssentiments facecolorg pltxlabel pltylabel quantity plttitle pltshow 输出 结果 如 下图 所示 可以 看到 对应 的 分数 如下 gtgtgte 情感 波动 分析 接下来 分析 每条 评论 的 波动 情况 代码 如下 所示 i print ssentiments ssentiments nparange sentimentslistk pltxlabel number pltylabel sentiment plttitle pltshow 输出 结果 如下 所示 呈现 一条 曲线 因为 抓取 的 评论 基本 都是 好评 所以 分数 基本 接近于 而 真实 分析 过程中 存在 好评 中 评 和 差 评 曲线 更加 规律 同时 在做 情感 分析 的 时候 我 看到 很多 论文 都是 将 情感 区间 从 转 换为 这样 的 曲线 更加 好看 位于 以上 的 是 积极 评论 反之 消极 评论 修改 代码 如下 获取 情感 分数 sourceopen i print ssentiments ssentiments 区间 转 换为 sentimentslist resultappend sentimentslisti ii 可视化 画图 nparange resultk pltxlabel number pltylabel sentiment plttitle pltshow 绘制 图形 如下 所示 情感 时间 分布 最后 补充 随 时间 分布 的 情感 分数 相关 建议 读者 可能 也 发现 抓取 的 博客 存在 重复 时间 不 均衡 等 现象 微 博 数据 还是 非常 不好 抓取 数据 卡 住了 很多人 也 请 读者 深入分析 下 情感 分析 通常 需 要和 评论 时间 结合起来 并 进行 舆情 预测 等 建议 读者 尝试 将 时间 结合 比如 王 树 义 老师 的 文章 基于 情感 分类 的 竞争 企业 新闻 文本 主题 挖掘 情感 分析 也是 可以 进行 评价 的 我们 前面 抓取 的 分为 星 评分 假设 位 一 星位 二 星 为 三星 为 四星 为 五星 这样 我们 可以 计算 它 的 准确率 召回 率 f 值 从而 评论 我 的 算法 好坏 作者 还有 很多 情感 分析 结合 幂 率 分布 的 知识 因为 需要 写文章 这里 暂时不 进行 分享 但是 这篇 基础 文章 对 初学者 仍然 有 一定 的 帮助 bosonnlp 也是 一个 比较 不错 的 情感 分析 包 建议 感兴趣 的 读者 学习 它 提供 了 相关 的 词典 如下 读者 如果 不太 擅长 写 代码 可以 尝试 使用 情感 分析 系统 五 总结 写到 这里 第四篇 疫情 分析 的 文章 就 讲解 完毕 希望 对 您 有所 帮助 尤其是 想 写 文本 挖掘 论文 的 读者 后续 还会 分享 舆情 分析 威胁 情报 溯源 知识 图谱 预测 预警 及 ai 和 nlp 应用 等 如果 文章 对 您 有所 帮助 将是 我 写作 的 最大 动力 作者 将 源代码 上传 至 github 大家 可以 直接 下载 你们 的 支持 就是 我 撰写 的 最大 动力 加油 同时 向 钟 院士 致敬 向 一线 工作者 致敬 侠之大者 为国为民 咱们 中国人 一生 的 最高 追求 为 天地 立 心 为 生民 立 命为 往 圣 继 绝学 为 万世 开 太平 以 一人 之 力系 万民 康乐 以 一身 犯 险 保 大业 安全 他们 真是 做 到了 武汉 加油 中国 加油 byeastmount 中午 点 于 贵阳 参考文献 python 数据 挖掘 课程 十三 wordcloud 词 云 配置 过程 及 词频 分析 eastmountpython 爬虫 爬 取 微 博 之战 疫情 用户 评 论及 详情 python 爬虫 selenium 爬 取 新浪 微 博 内容 及 用户 信息 python 爬虫 selenium 爬 取 新浪 微 博 客户端 用户 信息 热点话题 及 评论 上 python 爬虫 selenium 爬 取 新浪 微 博 移动 端 热点话题 及 评论 下 用 pyecharts 绘制 词 云 情感 分析 深入 snownlp 原理 和 实践 自然语言 处理 库 之 snownlp 王 树 义 老师 的 文章 基于 情感 分类 的 竞争 企业 新闻 文本 主题 挖掘 