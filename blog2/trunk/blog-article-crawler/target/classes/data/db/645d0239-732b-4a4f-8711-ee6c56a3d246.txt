万字 长文 总结 机器 学习 的 模型 评估 与 调 参 附 代码 下载 作者 翻译 amp 整理 sam 来源 samshare 目录 一 认识 管道 流 数据 导入 使用 管道 创建 工作流 二 k 折 交叉 验证 k 折 交叉 验证 原理 k 折 交叉 验证 实现 三 曲线 调 参 模型 准确度 绘制 学习曲线 得到 样 本数 与 准确率 的 关系 绘制 验证 曲线 得到 超 参 和 准确率 关系 四 网格 搜索 两层 for 循环 暴力 检索 构建 字典 暴力 检索 五 嵌套 交叉 验证 六 相关 评价 指标 混淆 矩阵 及其 实现 相关 评价 指标 实现 roc 曲线 及其 实现 认识 管道 流 今天 先 介绍 一下 管道 工作流 的 操作 管道 工作流 这个 概念 可能 有点 陌生 其实 可以 理解为 一个 容器 然后 把 我们 需要 进行 的 操作 都 封装 在 这个 管道 里面 进行 操作 比如 数据 标准化 特征 降 维 主 成分 分析 模型 预测 等等 下面 还 是以 一个 实例 来讲 解 数据 导入 与 预处理 本次 我们 导入 一个 二 分类 数据 集 它 包含 个 样本 首列 为 主键 id 第 列为 类别 值 m 恶性肿瘤 b 良性肿瘤 第 列 是 实 数值 的 特征 先 导入 数据 集 导入 相关 数据 集 print dfhead 使用 我们 学习 过 的 labelencoder 来 转化 类别 特征 将 目标 转为 变量 ylefittransform y letransform mb 划分 训练 验证 集 创建 训练 集 和 测试 集 使用 管道 创建 工作流 很多 机器 学习 算法 要求 特征 取值 范围 要 相同 因此 需 要对 特征 做 标准化 处理 此外 我们 还 想将 原始 的 维度 特征 压缩 至 更少 维度 这就 需要 用到 主 成分 分析 要用 pca 来 完成 再 接着 就可以 进行 logistic 回归 预测 了 pipeline 对象 接收 元组 构成 的 列表 作为 输入 每个 元组 第一个 值 作为 变量名 元组 第二个 元素 是 sklearn 中 的 transformer 或 estimator 管道 中间 每 一步 由 sklearn 中 的 transformer 构成 最后 一步 是 一个 estimator 本次 数据 集中 管道 包含 两个 中间 步骤 standardscaler 和 pca 其 都 属于 transformer 而 逻辑 斯 蒂 回归 分类 器 属于 estimator 本次 实例 当 管道 pipelr 执行 fit 方法 时 standardscaler 执行 fit 和 transform 方法 将 转换 后 的 数据 输入 给 pcapca 同样 执行 fit 和 transform 方法 最后 数据 输入 给 训练 一个 lr 模型 对于 管道 来说 中间 有 多少个 transformer 都可以 管道 的 工作方式 可以用 下图 来 展示 一定 要注意 管道 执行 fit 方法 而 transformer 要 执行 fittransform 上面 的 代码 实现 如下 用于 进行 数据 标准化 用于 进行 特征 降 维 用于 模型 预测 pcapca ncomponents randomstate pipelrfit xtrainytrain print xtestytest xtest testaccuracyk 折 交叉 验证 为什么 要 评估 模型 的 泛 化 能力 相信 这个 大家 应该 没有 疑惑 一个 模型 如果 性能 不好 要么 是因为 模型 过于 复杂 导致 过 拟合 高 方差 要么 是 模型 过于 简单 导致 导致 欠 拟合 高 偏差 如何 评估 它用 什么 数据 来 评估 它 成 为了 模型 评估 需要 重点 考虑 的 问题 我们 常规 做法 就是 将 数据 集 划 分为 部分 分 别是 训练 测试 和 验证 彼此之间 的 数据 不 重叠 但 如果 我们 遇 见了 数据量 不多 的 时候 这种 操作 就 显得 不太 现实 这个 时候 k 折 交叉 验证 就 发挥优势 了 k 折 交叉 验证 原理 先 不 多说 先 贴 一张 原理图 以 折 交叉 验证 为 例 k 折 交叉 验证 步骤 step 使用 不 重复 抽样 将 原始数据 随机 分为 k 份 step 其中 k 份 数据 用于 模型 训练 剩下 的 那份 数据 用于 测试 模型 step 重复 stepk 次 得到 k 个 模型 和他 的 评估 结果 step 计算 k 折 交叉 验证 结果 的 平均值 作为 参数 模型 的 性能 评估 k 折 交叉 验证 实现 k 折 交叉 验证 那么 k 的 取值 该 如何 确认 呢 一般 我们 默认 折 但 根据 实际情况 有所 调整 我们 要知道 当 k 很大 的 时候 你 需要 训练 的 模型 就会 很多 这 样子 对 效率 影响 较大 而且 每个 模型 的 训练 集 都 差不多 效果 也 差不多 我们 常用 的 k 值 在 我们 根据 k 折 交叉 验证 的 原理 步骤 在 sklearn 中 进行 折 交叉 验证 的 代码 实现 split xtrainytrain scoresfork traintest inenumerate kfold pipelrfit scoresappend score print knpbincount ytraintrain score print ncvaccuracyff npmean scores npstd scores output 当然 实际使用 的 时候 没必要 这 样子 写 sklearn 已经有 现成 封 装好 的 方法 直接 调用 即可 print print cvaccuracyff npmean scores npstd scores 曲线 调 参 我们 讲到 的 曲线 具体 指的是 学习曲线 learningcurve 和 验证 曲线 validationcurve 模型 准确率 accuracy 模型 准确率 反馈 了 模型 的 效果 大家 看下 图左 上 角子 的 模型 偏差 很高 它 的 训练 集 和 验证 集 准确率 都 很低 很 可能是 欠 拟合 解决 欠 拟合 的 方法 就是 增加 模型 参数 比如 构建 更多 的 特征 减小 正则 项 右上 角子 的 模型 方差 很高 表现 就是 训练 集 和 验证 集 准确率 相差太多 解决 过 拟合 的 方法 有 增大 训练 集 或者 降低 模型 复杂度 比如 增大 正则 项 或者 通过 特征 选择 减少 特征 数 右下角 的 模型 就 很好 绘制 学习曲线 得到 样 本数 与 准确率 的 关系 直接 上 代码 在 和 间 线性 的 取 个 值 cvnjobs trainmeannpmean trainscoresaxis trainstdnpstd trainscoresaxis testmeannpmean testscoresaxis teststdnpstd testscoresaxis pltplot pltfillbetween pltplot pltfillbetween pltgrid pltxlabel pltylabel accuracy pltlegend loclowerright pltylim plttightlayout pltshow learningcurve 中 的 trainsizes 参数 控制 产生 学习曲线 的 训练样本 的 绝对 相对 数量 此处 我们 设置 的 将 训练 集 大小 划 分为 个 相等 的 区间 在 和 之间 线性 的 取 个 值 learningcurve 默认 使用 分层 k 折 交叉 验证 计算 交叉 验证 的 准确率 我们 通过 cv 设置 k 下图 可以 看到 模型 在 测试 集 表现 很好 不过 训练 集 和 测试 集 的 准确率 还是 有 一段 小 间隔 可能是 模型 有 点过 拟合 绘制 验证 曲线 得到 超 参 和 准确率 关系 验证 曲线 是 用来 提高 模型 的 性能 验证 曲线 和 学习曲线 很 相近 不同 的 是 这里 画出 的 是 不同 参数 下 模型 的 准确率 而 不是 不同 训练 集 大小 下 的 准确率 trainmeannpmean trainscoresaxis trainstdnpstd trainscoresaxis testmeannpmean testscoresaxis teststdnpstd testscoresaxis pltplot pltfillbetween pltplot pltfillbetween pltgrid pltxscale log pltlegend loclowerright pltxlabel parameterc pltylabel accuracy pltylim plttightlayout pltshow 我们 得 到了 参数 c 的 验证 曲线 和 learningcurve 方法 很像 validationcurve 方法 使用 采样 k 折 交叉 验证 来 评估 模型 的 性 能在 validationcurve 内部 我们 设定 了 用来 评估 的 参数 这里 我们 设置 c 作为 观测 从 下图 可以 看出 最好 的 c 值 是 网格 搜索 网格 搜索 gridsearch 作为 调 参 很 常用 的 方法 这边 还是 要 简单 介绍 一 下在 我们 的 机器 学习 算法 中有 一类 参数 需要 人工 进行 设定 我们 称之为 超 参 也 就是 算法 中 的 参数 比如 学习 率 正则 项 系数 或者 决策树 的 深度 等 网格 搜索 就是 要 找到 一个 最优 的 参数 从而 使得 模型 的 效果 最佳 而 它 实现 的 原理 其实 就是 暴力 搜索 即 我们 事 先为 每个 参数 设定 一组 值 然后 穷举 各种 参数 组合 找到 最好 的 那一 组 两层 for 循环 暴力 检索 网格 搜索 的 结果 获得了 指定 的 最优 参 数值 c 为 gamma 为 print gammagammacc svmfit xtrainytrain xtestytest print 构建 字典 暴力 检索 网格 搜索 的 结果 获得了 指定 的 最优 参 数值 c 为 clfsvc randomstate gsgsfit xtrainytrain print gsbestscore print gsbestparams 中 paramgrid 参数 是 字典 构成 的 列表 对于 线性 svm 我们 只 评估 参数 c 对于 rbf 核 svm 我们 评估 c 和 gamma 最后 我们 通过 bestparmas 得到 最优 参数 组合 接着 我们 直接 利用 最优 参数 建模 bestestimator xtrainytrain print xtestytest 网格 搜索 虽然 不错 但是 穷举 过于 耗时 sklearn 中 还 实现 了 随机 搜索 使用 类 随机 采样 出 不同 的 参数 组合 嵌套 交叉 验证 嵌套 交叉 验证 选择 算 法外 循环 通过 k 折 等 进行 参数 优化 内 循环 使用 交叉 验证 对 特定 数据 集 进行 模型 选择 varma 和 simon 在 论文 中指 出 使用 嵌套 交叉 验证 得到 的 测试 集 误差 几乎 就是 真实 误差 嵌套 交叉 验证 外部 有 一个 k 折 交叉 验证 将 数据 分为 训练 集 和 测试 集 内部 交叉 验证 用于 选择 模型 算法 下图 演示 了 一个 折 外层 交叉 沿 则 和 折 内部 交叉 验证 组成 的 嵌套 交叉 验证 也 被称为 交叉 验证 我们 还是 用到 之前 的 数据 集 相关 包 的 导入 操作 这里 就 省略 了 svm 分类 器 的 预测 准确率 代码 实现 gsgridsearchcv print cvaccuracyff npmean scores npstd scores cvaccuracy 决策树 分类 器 的 预测 准确率 代码 实现 randomstate print cvaccuracyff npmean scores npstd scores cvaccuracy 相关 评价 指标 混淆 矩阵 及其 实现 混淆 矩阵 大家 应该 都有 听说过 大致 就是 长 下面 这 样子 的 所以有 几个 概念 需要 先 说明 tp truepositive 真 实为 预测 也 为 fn falsenegative 真 实为 预测 为 fp falsepositive 真 实为 预测 为 tn truenegative 真 实为 预测 也 为 所以 衍 生了 几个 常用 的 指标 分类 模型 总体 判断 的 准确率 包括 了 所有 class 的 总体 准确率 预测 为 的 准确 率真 实为 的 准确 率真 实为 的 准确率 预测 为 的 准确率 对于 某个 分类 综合 了 precision 和 recall 的 一个 判断 指标 fscore 的 值 是 从到 的 是 最好 是 最差 另外 一个 综合 precision 和 recall 的 标准 fscore 的 变形 再 举个 例子 混淆 矩阵 网络 上有 很多 文章 也 不用说 刻意 地 去 背 去 记 需要 的 时候 百度 一下 你 就 知道 混淆 矩阵 实现 代码 xtrainytrain xtest print confmat figsize axmatshow foriinrange confmatshape forjinrange confmatshape axtext pltxlabel predictedlabel pltylabel truelabel plttightlayout pltshow 相关 评价 指标 实现 分 别是 准确度 recall 以及 f 指标 的 实现 print print fffscore 指定 评价 指标 自动 选出 最优 模型 可以 通过 在 makescorer 中 设定 参数 确定 需要 用来 评价 的 指标 这里 用了 flscore 这个 函数 可以 直接 输出 结果 fscoreposlabel gsgsfit xtrainytrain print gsbestscore print gsbestparams 曲线 及其 实现 如果 需要 理解 roc 曲线 那你 就需要 先 了解 一下 混淆 矩阵 了 具体 的 内容 可以 查看 一下 之前 的 文章 这里 重点 引入 个 概念 真正 率 指的是 被 模型 正确 预测 的 正 样本 的 比 例假 正 率 指的是 被 模型 错误 预测 的 正 样本 的 比例 roc 曲线 概念 roc 接受者 操作 特征 其 显示 的 是 分类 器 的 真正 率 和 假 正 率 之间 的 关系 如 下图 所示 roc 曲线 有助于 比较 不同 分类 器 的 相对 性能 其 曲线 下方 的 面 积为 auc areaundercurve 其 面积 越大 则 分类 的 性能 越好 理想 的 分类 器 aucroc 曲线 绘制 对于 一个 特定 的 分类 器 和 测试数据 集 显然 只能 得到 一个 分类 结果 即 一组 fpr 和 tpr 结果 而要 得到 一个 曲线 我们 实际上 需要 一系列 fpr 和 tpr 的 值 那么 如何 处理 很简单 我们 可以 根据 模型 预测 的 概率 值 并且 设置 不同 的 阈值 来 获得 不同 的 预测 结果 什么意思 比如说 个 样本 真实 的 target 目标 标签 是 yc 模型 分类 器 将 预测 样本 为 的 概率 pc 我们 需要 选定 阈值 才 能把 概率 转 化为 类别 如果 我们 选定 阈值 为 那么 个 样本 被 分进 的 类别 如果 选定 结果 仍然 一样 如果 选 了 作为 阈值 那么 只有 样本 被 分进 之后 把 所有 得到 的 所有 分类 结果 计算 ftrptr 并 绘 制成 线 就可以 得到 roc 曲线 了当 threshold 阈值 取值 越多 roc 曲线 越 平滑 roc 曲线 代码 实现 pcapca ncomponents xtrainxtrain 因为 全部 特征 丢 进去 的话 预测 效果 太 好画 roc 曲线 不好看 哈哈哈 所以 只是 取了 个 特征 cvlist stratifiedkfold split xtrainytrain figpltfigure figsize alltprfori traintest inenumerate cv probaspipelrfit predictproba xtraintest meantprinterp meanfprfprtpr fprtpr pltplot areaf irocauc pltplot linestylecolor meantprlen cv meanfprmeantpr pltplot areaf meanauclw pltplot pltxlim pltylim pltxlabel pltylabel plttitle pltlegend loclowerright plttightlayout pltshow 查 看下 auc 和 准确率 的 结果 pipelrpipelrfit xtrainytrain xtest xtest print rocaucaccuracy 代码 链接 密码 cgg 推荐 阅读 算法 实现 太 难了 机器 学习 也 需要 开源 软件 tiktok 算法 背后 是 抖 音 用户 数据 想 多了 维度 爆炸 python 实现 数据压缩 如此 简单 马 小 峰 金融 科技界 的 区块 链 博士 java 二十五 载 正在 kotlin 化 